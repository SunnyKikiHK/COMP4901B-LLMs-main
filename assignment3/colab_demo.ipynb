{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8d3b43e0",
      "metadata": {
        "id": "8d3b43e0"
      },
      "source": [
        "###  Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "45c19e77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45c19e77",
        "outputId": "0d0bb864-b866-4f32-9773-127c892dcc17",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! mkdir -p /content/drive/MyDrive/COMP4901B-Homework3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420dc8b7",
      "metadata": {
        "id": "420dc8b7"
      },
      "source": [
        "### Clone Codebase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20bdbde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e20bdbde",
        "outputId": "d69184eb-b0e9-4087-8326-0ac8d98a1bae",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COMP4901B-LLMs'...\n",
            "remote: Enumerating objects: 232, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 232 (delta 40), reused 24 (delta 24), pack-reused 169 (from 1)\u001b[K\n",
            "Receiving objects: 100% (232/232), 798.55 KiB | 1.87 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "! mkdir -p /content/drive/MyDrive/COMP4901B-Homework3\n",
        "! cd /content/drive/MyDrive/COMP4901B-Homework3 && git clone https://github.com/hkust-nlp/COMP4901B-LLMs.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c6cfe0",
      "metadata": {
        "id": "29c6cfe0"
      },
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b5510016",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5510016",
        "outputId": "90867841-69b8-4132-d585-29e97d223f17",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.23.0) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: transformers==4.57.1 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]==4.57.1) (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.1->transformers[torch]==4.57.1) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]==4.57.1) (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from transformers[torch]==4.57.1) (1.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.26.0->transformers[torch]==4.57.1) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->transformers[torch]==4.57.1) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->transformers[torch]==4.57.1) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.1->transformers[torch]==4.57.1) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->transformers[torch]==4.57.1) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1->transformers[torch]==4.57.1) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1->transformers[torch]==4.57.1) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1->transformers[torch]==4.57.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.57.1->transformers[torch]==4.57.1) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]==4.57.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->transformers[torch]==4.57.1) (3.0.3)\n",
            "Requirement already satisfied: vllm==0.10.2 in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.0.8)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.57.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.121.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.13.2)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.109.1)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.11.10)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (11.3.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.12.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.11.3)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.7.30)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.11)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.23 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.1.23)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.20.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.2.1.1.post6)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (1.8.5)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.17.0)\n",
            "Requirement already satisfied: setuptools<80,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (79.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.11.0)\n",
            "Requirement already satisfied: depyf==0.19.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.19.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (3.1.2)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.16.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.13.0)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.4.2)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (5.7.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (1.3.7)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.0.8)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.61.2)\n",
            "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.10.2) (2.51.1)\n",
            "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.23.0+cu126)\n",
            "Requirement already satisfied: xformers==0.0.32.post1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.10.2) (0.0.32.post1)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.11.0->vllm==0.10.2) (2.4.6)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm==0.10.2) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm==0.10.2) (0.3.8)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm==0.10.2) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm==0.10.2) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm==0.10.2) (0.44.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->vllm==0.10.2) (3.4.0)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.49.3)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.0.4)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.0.16)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.10.2) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.38.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (4.25.1)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.10.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm==0.10.2) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm==0.10.2) (0.4.2)\n",
            "Requirement already satisfied: click!=8.3.0,>=7.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2) (8.2.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.10.2) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.10.2) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.10.2) (2025.10.5)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm==0.10.2) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.2->vllm==0.10.2) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.10.2) (1.22.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.8.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.20.0)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.15.1)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm==0.10.2) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->vllm==0.10.2) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.28.0)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (24.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->vllm==0.10.2) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.22.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm==0.10.2) (0.8.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (0.13.1)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (1.0.0)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.7.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.44.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm==0.10.2) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.10.2) (0.1.2)\n",
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.12/dist-packages (0.18.2)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.12/dist-packages (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.12/dist-packages (1.0.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (4.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: datasets==4.0.0 in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets==4.0.0) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets==4.0.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets==4.0.0) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.0.0) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==4.0.0) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==4.0.0) (1.17.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from peft) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from peft) (6.0.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft) (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from peft) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft) (1.11.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from peft) (0.6.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from peft) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (79.0.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->peft) (0.22.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\n",
            "Fetching 10 files: 100% 10/10 [00:00<00:00, 137.25it/s]\n",
            "Fetching 6 files: 100% 6/6 [00:00<00:00, 144.61it/s]\n"
          ]
        }
      ],
      "source": [
        "! cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1 code evaulation for q1"
      ],
      "metadata": {
        "id": "1g5V_geSlmBY"
      },
      "id": "1g5V_geSlmBY"
    },
    {
      "cell_type": "code",
      "source": [
        "! cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3/ && python tests/test_format_prompts.py"
      ],
      "metadata": {
        "id": "MmryTBAWlrtb",
        "outputId": "ef7f48ea-131f-4f00-bc11-ccbd8f8d76a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "id": "MmryTBAWlrtb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SANITY CHECK: format_prompts()\n",
            "======================================================================\n",
            "\n",
            "This script tests your implementation of the format_prompts function.\n",
            "It compares your outputs with expected reference outputs.\n",
            "\n",
            "\n",
            "======================================================================\n",
            "TEST 2: Few-shot without chat template\n",
            "======================================================================\n",
            "2025-11-13 09:43:54.067356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763027034.487824    6130 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763027034.594252    6130 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763027035.283583    6130 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763027035.283628    6130 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763027035.283633    6130 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763027035.283637    6130 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-13 09:43:55.353037: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 11-13 09:44:17 [__init__.py:220] No platform detected, vLLM is running on UnspecifiedPlatform\n",
            "WARNING 11-13 09:44:20 [_custom_ops.py:20] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')\n",
            " PASSED: Few-shot prompt contains example problems\n",
            "\n",
            "======================================================================\n",
            "TEST 3: With chat template (using Qwen tokenizer)\n",
            "======================================================================\n",
            "Loading tokenizer: Qwen/Qwen2.5-0.5B-Instruct\n",
            "tokenizer_config.json: 7.30kB [00:00, 9.93MB/s]\n",
            "vocab.json: 2.78MB [00:00, 27.6MB/s]\n",
            "merges.txt: 1.67MB [00:00, 30.8MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 55.6MB/s]\n",
            " PASSED: Chat template markers found in prompt\n",
            "\n",
            "Formatted prompt preview:\n",
            "<|im_start|>system\n",
            "You are a helpful math tutor.<|im_end|>\n",
            "<|im_start|>user\n",
            "If John has 5 apples and gives 2 to Mary, how many apples does he have left?\n",
            "Please reason step by step, and put your final ...\n",
            "\n",
            "======================================================================\n",
            "TEST 4: System message inclusion\n",
            "======================================================================\n",
            " PASSED: System message appears to be included\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            " PASSED: Few-shot without chat\n",
            " PASSED: With chat template\n",
            " PASSED: System message\n",
            "\n",
            "Total: 3/3 passed\n",
            "\n",
            " All tests passed! Your format_prompts implementation looks correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfe18aa7",
      "metadata": {
        "id": "dfe18aa7"
      },
      "source": [
        "### Q4 Start The Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Default"
      ],
      "metadata": {
        "id": "cwGpX4aNIjXF"
      },
      "id": "cwGpX4aNIjXF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76f6abed",
      "metadata": {
        "id": "76f6abed",
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68305762-e469-4d37-a6fa-d8218f85deae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "GSM8K Self-Improving Training Pipeline\n",
            "========================================\n",
            "Run Name: first-run\n",
            "Initial Model: Qwen3-0.6B\n",
            "Pipeline Directory: ckpt/first-run\n",
            "Number of Iterations: 1\n",
            "\n",
            "Inference Settings:\n",
            "  Dataset Split: train\n",
            "  Number of Queries: 2000\n",
            "  Max Tokens: 512\n",
            "  Temperature: 1.0\n",
            "  Top-p: 1\n",
            "  Top-k: -1\n",
            "  Number of Rollouts: 8\n",
            "  Tensor Parallel: 1\n",
            "  Mode: Zero-shot\n",
            "  Chat Template: Enabled\n",
            "  Thinking Mode: Disabled\n",
            "\n",
            "Training Settings:\n",
            "  Learning Rate: 2e-5\n",
            "  Total Batch Size: 128\n",
            "  Batch Size Per Device: 1\n",
            "  Gradient Accumulation Steps: 128 (auto-calculated)\n",
            "  Number of Epochs: 1\n",
            "  Save Steps: 30\n",
            "  LoRA Rank: 64\n",
            "  Model Max Length: 712 (auto-calculated: MAX_TOKENS + 200)\n",
            "========================================\n",
            "\n",
            "========================================\n",
            "ITERATION 0 / 0\n",
            "========================================\n",
            "Model: Qwen3-0.6B\n",
            "\n",
            "[Step 1/4] Running inference...\n",
            "Output: ckpt/first-run/iteration_0/inference.jsonl\n",
            "\n",
            "2025-11-14 11:42:24.446372: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-14 11:42:24.463881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763120544.485531    3843 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763120544.492055    3843 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763120544.508552    3843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120544.508578    3843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120544.508580    3843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120544.508582    3843 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-14 11:42:24.513471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 11-14 11:42:33 [__init__.py:216] Automatically detected platform cuda.\n",
            "INFO 11-14 11:42:46 [utils.py:328] non-default args: {'tokenizer': 'Qwen3-0.6B', 'gpu_memory_utilization': 0.8, 'disable_log_stats': True, 'model': 'Qwen3-0.6B'}\n",
            "INFO 11-14 11:43:04 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "INFO 11-14 11:43:04 [__init__.py:1815] Using max model len 40960\n",
            "INFO 11-14 11:43:06 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 11-14 11:43:07 [__init__.py:2974] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
            "2025-11-14 11:43:12.073903: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763120592.095164    4156 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763120592.101696    4156 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763120592.117735    4156 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120592.117761    4156 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120592.117764    4156 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763120592.117766    4156 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "INFO 11-14 11:43:19 [__init__.py:216] Automatically detected platform cuda.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:20 [core.py:654] Waiting for init message from front-end.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:20 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='Qwen3-0.6B', speculative_config=None, tokenizer='Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen3-0.6B, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "[W1114 11:43:23.497668660 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:23 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m WARNING 11-14 11:43:23 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:23 [gpu_model_runner.py:2338] Starting to load model Qwen3-0.6B...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:23 [gpu_model_runner.py:2370] Loading model from scratch...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:23 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.86s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:21<00:00, 21.86s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m \n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:45 [default_loader.py:268] Loading weights took 21.88 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:46 [gpu_model_runner.py:2392] Model loading took 1.1201 GiB and 22.256874 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:55 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/44c42810b9/rank_0_0/backbone for vLLM's torch.compile\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:43:55 [backends.py:550] Dynamo bytecode transform time: 8.30 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m [rank0]:W1114 11:43:56.675000 4156 torch/_inductor/utils.py:1436] [0/0] Not enough SMs to use max_autotune_gemm mode\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:01 [backends.py:194] Cache the graph for dynamic shape for later use\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:28 [backends.py:215] Compiling a graph for dynamic shape takes 32.38 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:31 [monitor.py:34] torch.compile takes 40.68 s in total\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:33 [gpu_worker.py:298] Available KV cache memory: 15.19 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:33 [kv_cache_utils.py:864] GPU KV cache size: 142,208 tokens\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:33 [kv_cache_utils.py:868] Maximum concurrency for 40,960 tokens per request: 3.47x\n",
            "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|| 67/67 [00:03<00:00, 22.01it/s]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:37 [gpu_model_runner.py:3118] Graph capturing finished in 4 secs, took 0.47 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:37 [gpu_worker.py:391] Free memory on device (21.95/22.16 GiB) on startup. Desired GPU memory utilization is (0.8, 17.73 GiB). Actual usage is 1.12 GiB for weight, 1.4 GiB for peak activation, 0.02 GiB for non-torch memory, and 0.47 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=15646582988` to fit into requested memory, or `--kv-cache-memory=20175461376` to fully utilize gpu memory. Current kv cache memory in use is 16311380172 bytes.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=4156)\u001b[0;0m INFO 11-14 11:44:37 [core.py:218] init engine (profile, create kv cache, warmup model) took 51.39 seconds\n",
            "INFO 11-14 11:44:39 [llm.py:295] Supported_tasks: ['generate']\n",
            "INFO 11-14 11:44:39 [__init__.py:36] No IOProcessor plugins requested by the model\n",
            "Adding requests: 100%|| 2000/2000 [00:02<00:00, 893.40it/s] \n",
            "Processed prompts: 100%|| 16000/16000 [13:16<00:00, 20.10it/s, est. speed input: 1739.72 toks/s, output: 4991.45 toks/s]\n",
            "[rank0]:[W1114 11:57:59.326135498 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            " Inference completed\n",
            "\n",
            "[Step 2/4] Running evaluation...\n",
            "Output: ckpt/first-run/iteration_0/evaluation.jsonl\n",
            "\n",
            "Loading data from ckpt/first-run/iteration_0/inference.jsonl\n",
            "Loaded 16000 examples\n",
            "\n",
            "Basic Evaluation Results:\n",
            "Total examples: 16000\n",
            "Correct answers: 9338\n",
            "Overall Accuracy: 58.36%\n",
            "\n",
            "Detected multiple rollouts: 2000 unique questions with 16000 total rollouts\n",
            "\n",
            "============================================================\n",
            "Multiple Rollout Metrics:\n",
            "============================================================\n",
            "k     avg@k           pass@k         \n",
            "------------------------------------------------------------\n",
            "1     0.5805          0.5805         \n",
            "2     0.5755          0.7065         \n",
            "3     0.5782          0.7790         \n",
            "4     0.5787          0.8065         \n",
            "5     0.5809          0.8285         \n",
            "6     0.5820          0.8460         \n",
            "7     0.5822          0.8600         \n",
            "8     0.5836          0.8755         \n",
            "============================================================\n",
            "\n",
            "Metrics saved to ckpt/first-run/iteration_0/evaluation_metrics.json\n",
            "\n",
            "Results saved to ckpt/first-run/iteration_0/evaluation.jsonl\n",
            " Evaluation completed\n",
            "\n",
            "[Step 3/4] Filtering correct examples...\n",
            "Output: ckpt/first-run/iteration_0/correct_examples.jsonl\n",
            "\n",
            "Loading data from ckpt/first-run/iteration_0/evaluation.jsonl\n",
            "Filtered 9338 correct examples out of 16000 total examples\n",
            "Accuracy: 58.36%\n",
            "Saved to ckpt/first-run/iteration_0/correct_examples.jsonl\n",
            "Number of correct examples: 9338\n",
            " Filtering completed\n",
            "\n",
            "[Step 4/4] Training on correct examples...\n",
            "Training data: ckpt/first-run/iteration_0/correct_examples.jsonl\n",
            "New model will be saved to: ckpt/first-run/models/model_iter_1\n",
            "\n",
            "\n",
            "2025-11-14 11:58:16.249834: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-14 11:58:16.268720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763121496.290789    8657 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763121496.297503    8657 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763121496.314997    8657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763121496.315026    8657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763121496.315028    8657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763121496.315030    8657 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-14 11:58:16.320411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading model in torch.bfloat16 precision.\n",
            "Found linear module: model.layers.0.self_attn.q_proj\n",
            "Found linear module: model.layers.0.self_attn.k_proj\n",
            "Found linear module: model.layers.0.self_attn.v_proj\n",
            "Found linear module: model.layers.0.self_attn.o_proj\n",
            "Found linear module: model.layers.0.mlp.gate_proj\n",
            "Found linear module: model.layers.0.mlp.up_proj\n",
            "Found linear module: model.layers.0.mlp.down_proj\n",
            "Found linear module: model.layers.1.self_attn.q_proj\n",
            "Found linear module: model.layers.1.self_attn.k_proj\n",
            "Found linear module: model.layers.1.self_attn.v_proj\n",
            "Found linear module: model.layers.1.self_attn.o_proj\n",
            "Found linear module: model.layers.1.mlp.gate_proj\n",
            "Found linear module: model.layers.1.mlp.up_proj\n",
            "Found linear module: model.layers.1.mlp.down_proj\n",
            "Found linear module: model.layers.2.self_attn.q_proj\n",
            "Found linear module: model.layers.2.self_attn.k_proj\n",
            "Found linear module: model.layers.2.self_attn.v_proj\n",
            "Found linear module: model.layers.2.self_attn.o_proj\n",
            "Found linear module: model.layers.2.mlp.gate_proj\n",
            "Found linear module: model.layers.2.mlp.up_proj\n",
            "Found linear module: model.layers.2.mlp.down_proj\n",
            "Found linear module: model.layers.3.self_attn.q_proj\n",
            "Found linear module: model.layers.3.self_attn.k_proj\n",
            "Found linear module: model.layers.3.self_attn.v_proj\n",
            "Found linear module: model.layers.3.self_attn.o_proj\n",
            "Found linear module: model.layers.3.mlp.gate_proj\n",
            "Found linear module: model.layers.3.mlp.up_proj\n",
            "Found linear module: model.layers.3.mlp.down_proj\n",
            "Found linear module: model.layers.4.self_attn.q_proj\n",
            "Found linear module: model.layers.4.self_attn.k_proj\n",
            "Found linear module: model.layers.4.self_attn.v_proj\n",
            "Found linear module: model.layers.4.self_attn.o_proj\n",
            "Found linear module: model.layers.4.mlp.gate_proj\n",
            "Found linear module: model.layers.4.mlp.up_proj\n",
            "Found linear module: model.layers.4.mlp.down_proj\n",
            "Found linear module: model.layers.5.self_attn.q_proj\n",
            "Found linear module: model.layers.5.self_attn.k_proj\n",
            "Found linear module: model.layers.5.self_attn.v_proj\n",
            "Found linear module: model.layers.5.self_attn.o_proj\n",
            "Found linear module: model.layers.5.mlp.gate_proj\n",
            "Found linear module: model.layers.5.mlp.up_proj\n",
            "Found linear module: model.layers.5.mlp.down_proj\n",
            "Found linear module: model.layers.6.self_attn.q_proj\n",
            "Found linear module: model.layers.6.self_attn.k_proj\n",
            "Found linear module: model.layers.6.self_attn.v_proj\n",
            "Found linear module: model.layers.6.self_attn.o_proj\n",
            "Found linear module: model.layers.6.mlp.gate_proj\n",
            "Found linear module: model.layers.6.mlp.up_proj\n",
            "Found linear module: model.layers.6.mlp.down_proj\n",
            "Found linear module: model.layers.7.self_attn.q_proj\n",
            "Found linear module: model.layers.7.self_attn.k_proj\n",
            "Found linear module: model.layers.7.self_attn.v_proj\n",
            "Found linear module: model.layers.7.self_attn.o_proj\n",
            "Found linear module: model.layers.7.mlp.gate_proj\n",
            "Found linear module: model.layers.7.mlp.up_proj\n",
            "Found linear module: model.layers.7.mlp.down_proj\n",
            "Found linear module: model.layers.8.self_attn.q_proj\n",
            "Found linear module: model.layers.8.self_attn.k_proj\n",
            "Found linear module: model.layers.8.self_attn.v_proj\n",
            "Found linear module: model.layers.8.self_attn.o_proj\n",
            "Found linear module: model.layers.8.mlp.gate_proj\n",
            "Found linear module: model.layers.8.mlp.up_proj\n",
            "Found linear module: model.layers.8.mlp.down_proj\n",
            "Found linear module: model.layers.9.self_attn.q_proj\n",
            "Found linear module: model.layers.9.self_attn.k_proj\n",
            "Found linear module: model.layers.9.self_attn.v_proj\n",
            "Found linear module: model.layers.9.self_attn.o_proj\n",
            "Found linear module: model.layers.9.mlp.gate_proj\n",
            "Found linear module: model.layers.9.mlp.up_proj\n",
            "Found linear module: model.layers.9.mlp.down_proj\n",
            "Found linear module: model.layers.10.self_attn.q_proj\n",
            "Found linear module: model.layers.10.self_attn.k_proj\n",
            "Found linear module: model.layers.10.self_attn.v_proj\n",
            "Found linear module: model.layers.10.self_attn.o_proj\n",
            "Found linear module: model.layers.10.mlp.gate_proj\n",
            "Found linear module: model.layers.10.mlp.up_proj\n",
            "Found linear module: model.layers.10.mlp.down_proj\n",
            "Found linear module: model.layers.11.self_attn.q_proj\n",
            "Found linear module: model.layers.11.self_attn.k_proj\n",
            "Found linear module: model.layers.11.self_attn.v_proj\n",
            "Found linear module: model.layers.11.self_attn.o_proj\n",
            "Found linear module: model.layers.11.mlp.gate_proj\n",
            "Found linear module: model.layers.11.mlp.up_proj\n",
            "Found linear module: model.layers.11.mlp.down_proj\n",
            "Found linear module: model.layers.12.self_attn.q_proj\n",
            "Found linear module: model.layers.12.self_attn.k_proj\n",
            "Found linear module: model.layers.12.self_attn.v_proj\n",
            "Found linear module: model.layers.12.self_attn.o_proj\n",
            "Found linear module: model.layers.12.mlp.gate_proj\n",
            "Found linear module: model.layers.12.mlp.up_proj\n",
            "Found linear module: model.layers.12.mlp.down_proj\n",
            "Found linear module: model.layers.13.self_attn.q_proj\n",
            "Found linear module: model.layers.13.self_attn.k_proj\n",
            "Found linear module: model.layers.13.self_attn.v_proj\n",
            "Found linear module: model.layers.13.self_attn.o_proj\n",
            "Found linear module: model.layers.13.mlp.gate_proj\n",
            "Found linear module: model.layers.13.mlp.up_proj\n",
            "Found linear module: model.layers.13.mlp.down_proj\n",
            "Found linear module: model.layers.14.self_attn.q_proj\n",
            "Found linear module: model.layers.14.self_attn.k_proj\n",
            "Found linear module: model.layers.14.self_attn.v_proj\n",
            "Found linear module: model.layers.14.self_attn.o_proj\n",
            "Found linear module: model.layers.14.mlp.gate_proj\n",
            "Found linear module: model.layers.14.mlp.up_proj\n",
            "Found linear module: model.layers.14.mlp.down_proj\n",
            "Found linear module: model.layers.15.self_attn.q_proj\n",
            "Found linear module: model.layers.15.self_attn.k_proj\n",
            "Found linear module: model.layers.15.self_attn.v_proj\n",
            "Found linear module: model.layers.15.self_attn.o_proj\n",
            "Found linear module: model.layers.15.mlp.gate_proj\n",
            "Found linear module: model.layers.15.mlp.up_proj\n",
            "Found linear module: model.layers.15.mlp.down_proj\n",
            "Found linear module: model.layers.16.self_attn.q_proj\n",
            "Found linear module: model.layers.16.self_attn.k_proj\n",
            "Found linear module: model.layers.16.self_attn.v_proj\n",
            "Found linear module: model.layers.16.self_attn.o_proj\n",
            "Found linear module: model.layers.16.mlp.gate_proj\n",
            "Found linear module: model.layers.16.mlp.up_proj\n",
            "Found linear module: model.layers.16.mlp.down_proj\n",
            "Found linear module: model.layers.17.self_attn.q_proj\n",
            "Found linear module: model.layers.17.self_attn.k_proj\n",
            "Found linear module: model.layers.17.self_attn.v_proj\n",
            "Found linear module: model.layers.17.self_attn.o_proj\n",
            "Found linear module: model.layers.17.mlp.gate_proj\n",
            "Found linear module: model.layers.17.mlp.up_proj\n",
            "Found linear module: model.layers.17.mlp.down_proj\n",
            "Found linear module: model.layers.18.self_attn.q_proj\n",
            "Found linear module: model.layers.18.self_attn.k_proj\n",
            "Found linear module: model.layers.18.self_attn.v_proj\n",
            "Found linear module: model.layers.18.self_attn.o_proj\n",
            "Found linear module: model.layers.18.mlp.gate_proj\n",
            "Found linear module: model.layers.18.mlp.up_proj\n",
            "Found linear module: model.layers.18.mlp.down_proj\n",
            "Found linear module: model.layers.19.self_attn.q_proj\n",
            "Found linear module: model.layers.19.self_attn.k_proj\n",
            "Found linear module: model.layers.19.self_attn.v_proj\n",
            "Found linear module: model.layers.19.self_attn.o_proj\n",
            "Found linear module: model.layers.19.mlp.gate_proj\n",
            "Found linear module: model.layers.19.mlp.up_proj\n",
            "Found linear module: model.layers.19.mlp.down_proj\n",
            "Found linear module: model.layers.20.self_attn.q_proj\n",
            "Found linear module: model.layers.20.self_attn.k_proj\n",
            "Found linear module: model.layers.20.self_attn.v_proj\n",
            "Found linear module: model.layers.20.self_attn.o_proj\n",
            "Found linear module: model.layers.20.mlp.gate_proj\n",
            "Found linear module: model.layers.20.mlp.up_proj\n",
            "Found linear module: model.layers.20.mlp.down_proj\n",
            "Found linear module: model.layers.21.self_attn.q_proj\n",
            "Found linear module: model.layers.21.self_attn.k_proj\n",
            "Found linear module: model.layers.21.self_attn.v_proj\n",
            "Found linear module: model.layers.21.self_attn.o_proj\n",
            "Found linear module: model.layers.21.mlp.gate_proj\n",
            "Found linear module: model.layers.21.mlp.up_proj\n",
            "Found linear module: model.layers.21.mlp.down_proj\n",
            "Found linear module: model.layers.22.self_attn.q_proj\n",
            "Found linear module: model.layers.22.self_attn.k_proj\n",
            "Found linear module: model.layers.22.self_attn.v_proj\n",
            "Found linear module: model.layers.22.self_attn.o_proj\n",
            "Found linear module: model.layers.22.mlp.gate_proj\n",
            "Found linear module: model.layers.22.mlp.up_proj\n",
            "Found linear module: model.layers.22.mlp.down_proj\n",
            "Found linear module: model.layers.23.self_attn.q_proj\n",
            "Found linear module: model.layers.23.self_attn.k_proj\n",
            "Found linear module: model.layers.23.self_attn.v_proj\n",
            "Found linear module: model.layers.23.self_attn.o_proj\n",
            "Found linear module: model.layers.23.mlp.gate_proj\n",
            "Found linear module: model.layers.23.mlp.up_proj\n",
            "Found linear module: model.layers.23.mlp.down_proj\n",
            "Found linear module: model.layers.24.self_attn.q_proj\n",
            "Found linear module: model.layers.24.self_attn.k_proj\n",
            "Found linear module: model.layers.24.self_attn.v_proj\n",
            "Found linear module: model.layers.24.self_attn.o_proj\n",
            "Found linear module: model.layers.24.mlp.gate_proj\n",
            "Found linear module: model.layers.24.mlp.up_proj\n",
            "Found linear module: model.layers.24.mlp.down_proj\n",
            "Found linear module: model.layers.25.self_attn.q_proj\n",
            "Found linear module: model.layers.25.self_attn.k_proj\n",
            "Found linear module: model.layers.25.self_attn.v_proj\n",
            "Found linear module: model.layers.25.self_attn.o_proj\n",
            "Found linear module: model.layers.25.mlp.gate_proj\n",
            "Found linear module: model.layers.25.mlp.up_proj\n",
            "Found linear module: model.layers.25.mlp.down_proj\n",
            "Found linear module: model.layers.26.self_attn.q_proj\n",
            "Found linear module: model.layers.26.self_attn.k_proj\n",
            "Found linear module: model.layers.26.self_attn.v_proj\n",
            "Found linear module: model.layers.26.self_attn.o_proj\n",
            "Found linear module: model.layers.26.mlp.gate_proj\n",
            "Found linear module: model.layers.26.mlp.up_proj\n",
            "Found linear module: model.layers.26.mlp.down_proj\n",
            "Found linear module: model.layers.27.self_attn.q_proj\n",
            "Found linear module: model.layers.27.self_attn.k_proj\n",
            "Found linear module: model.layers.27.self_attn.v_proj\n",
            "Found linear module: model.layers.27.self_attn.o_proj\n",
            "Found linear module: model.layers.27.mlp.gate_proj\n",
            "Found linear module: model.layers.27.mlp.up_proj\n",
            "Found linear module: model.layers.27.mlp.down_proj\n",
            "Found linear module: lm_head\n",
            "Model type detected: qwen3\n",
            "Auto-selected LoRA target modules: ['q_proj', 'down_proj', 'k_proj', 'up_proj', 'gate_proj', 'o_proj', 'v_proj']\n",
            "Using GSM8K self-training mode - input already contains chat template\n",
            "Loaded 9338 examples from ckpt/first-run/iteration_0/correct_examples.jsonl\n",
            "Cache metadata mismatch for key 'data_mtime': expected 1763121490.0, found 1763102020.0. Regenerating.\n",
            "Tokenizing GSM8K examples: 100%|| 9338/9338 [00:19<00:00, 481.04it/s]\n",
            "/content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3/train_gsm8k_self_training_lora.py:665: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "wandb: Currently logged in as: lamyeungkong0108 (lamyeungkong0108-the-hong-kong-university-of-science-and) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: Tracking run with wandb version 0.22.3\n",
            "wandb: Run data is saved locally in /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3/wandb/run-20251114_115913-q55p38u7\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run brisk-forest-2\n",
            "wandb:  View project at https://wandb.ai/lamyeungkong0108-the-hong-kong-university-of-science-and/COMP4901B-Homework3\n",
            "wandb:  View run at https://wandb.ai/lamyeungkong0108-the-hong-kong-university-of-science-and/COMP4901B-Homework3/runs/q55p38u7\n",
            "Saved preprocessed features to ckpt/first-run/iteration_0/correct_examples_gsm8k_processed.pickle.\n",
            "#train 9151, #eval 187\n",
            "100%|| 72/72 [1:01:24<00:00, 51.17s/it]\n",
            "{'loss': 0.2842, 'grad_norm': 0.0412321574985981, 'learning_rate': 2e-05, 'epoch': 0.01}\n",
            "{'loss': 0.2738, 'grad_norm': 0.040876783430576324, 'learning_rate': 1.999048221581858e-05, 'epoch': 0.03}\n",
            "{'loss': 0.2756, 'grad_norm': 0.039690688252449036, 'learning_rate': 1.9961946980917457e-05, 'epoch': 0.04}\n",
            "{'loss': 0.2788, 'grad_norm': 0.042680516839027405, 'learning_rate': 1.9914448613738107e-05, 'epoch': 0.06}\n",
            "{'loss': 0.2809, 'grad_norm': 0.04258733242750168, 'learning_rate': 1.9848077530122083e-05, 'epoch': 0.07}\n",
            "{'loss': 0.3023, 'grad_norm': 0.040956296026706696, 'learning_rate': 1.9762960071199334e-05, 'epoch': 0.08}\n",
            "{'loss': 0.2837, 'grad_norm': 0.046012185513973236, 'learning_rate': 1.9659258262890683e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2852, 'grad_norm': 0.04344983398914337, 'learning_rate': 1.953716950748227e-05, 'epoch': 0.11}\n",
            "{'loss': 0.3043, 'grad_norm': 0.04215284064412117, 'learning_rate': 1.9396926207859085e-05, 'epoch': 0.13}\n",
            "{'loss': 0.2864, 'grad_norm': 0.041301827877759933, 'learning_rate': 1.9238795325112867e-05, 'epoch': 0.14}\n",
            "{'loss': 0.3106, 'grad_norm': 0.0407261960208416, 'learning_rate': 1.9063077870366504e-05, 'epoch': 0.15}\n",
            "{'loss': 0.2848, 'grad_norm': 0.040137290954589844, 'learning_rate': 1.887010833178222e-05, 'epoch': 0.17}\n",
            "{'loss': 0.3131, 'grad_norm': 0.0441724956035614, 'learning_rate': 1.866025403784439e-05, 'epoch': 0.18}\n",
            "{'loss': 0.3004, 'grad_norm': 0.04114912077784538, 'learning_rate': 1.843391445812886e-05, 'epoch': 0.2}\n",
            "{'loss': 0.3012, 'grad_norm': 0.041343312710523605, 'learning_rate': 1.819152044288992e-05, 'epoch': 0.21}\n",
            "{'loss': 0.3138, 'grad_norm': 0.045458462089300156, 'learning_rate': 1.7933533402912354e-05, 'epoch': 0.22}\n",
            "{'loss': 0.2901, 'grad_norm': 0.04221639037132263, 'learning_rate': 1.766044443118978e-05, 'epoch': 0.24}\n",
            "{'loss': 0.3004, 'grad_norm': 0.041205115616321564, 'learning_rate': 1.737277336810124e-05, 'epoch': 0.25}\n",
            "{'loss': 0.2917, 'grad_norm': 0.04758389666676521, 'learning_rate': 1.7071067811865477e-05, 'epoch': 0.27}\n",
            "{'loss': 0.2836, 'grad_norm': 0.045194391161203384, 'learning_rate': 1.6755902076156606e-05, 'epoch': 0.28}\n",
            "{'loss': 0.3034, 'grad_norm': 0.04089658707380295, 'learning_rate': 1.6427876096865394e-05, 'epoch': 0.29}\n",
            "{'loss': 0.279, 'grad_norm': 0.041532088071107864, 'learning_rate': 1.608761429008721e-05, 'epoch': 0.31}\n",
            "{'loss': 0.2823, 'grad_norm': 0.039261385798454285, 'learning_rate': 1.573576436351046e-05, 'epoch': 0.32}\n",
            "{'loss': 0.2984, 'grad_norm': 0.04346533119678497, 'learning_rate': 1.5372996083468242e-05, 'epoch': 0.34}\n",
            "{'loss': 0.2818, 'grad_norm': 0.04092961177229881, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.35}\n",
            "{'loss': 0.3003, 'grad_norm': 0.04204783961176872, 'learning_rate': 1.4617486132350343e-05, 'epoch': 0.36}\n",
            "{'loss': 0.2885, 'grad_norm': 0.04121629521250725, 'learning_rate': 1.4226182617406996e-05, 'epoch': 0.38}\n",
            "{'loss': 0.2815, 'grad_norm': 0.04102322831749916, 'learning_rate': 1.3826834323650899e-05, 'epoch': 0.39}\n",
            "{'loss': 0.2854, 'grad_norm': 0.03983001038432121, 'learning_rate': 1.342020143325669e-05, 'epoch': 0.41}\n",
            "{'loss': 0.2989, 'grad_norm': 0.03859668970108032, 'learning_rate': 1.300705799504273e-05, 'epoch': 0.42}\n",
            "{'loss': 0.2837, 'grad_norm': 0.0408283956348896, 'learning_rate': 1.2588190451025209e-05, 'epoch': 0.43}\n",
            "{'loss': 0.2856, 'grad_norm': 0.040170829743146896, 'learning_rate': 1.2164396139381029e-05, 'epoch': 0.45}\n",
            "{'loss': 0.2697, 'grad_norm': 0.03837982937693596, 'learning_rate': 1.1736481776669307e-05, 'epoch': 0.46}\n",
            "{'loss': 0.3013, 'grad_norm': 0.04542221501469612, 'learning_rate': 1.130526192220052e-05, 'epoch': 0.48}\n",
            "{'loss': 0.2877, 'grad_norm': 0.03982899710536003, 'learning_rate': 1.0871557427476585e-05, 'epoch': 0.49}\n",
            "{'loss': 0.2936, 'grad_norm': 0.04119272157549858, 'learning_rate': 1.0436193873653362e-05, 'epoch': 0.5}\n",
            "{'loss': 0.2878, 'grad_norm': 0.042690955102443695, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
            "{'loss': 0.27, 'grad_norm': 0.04045286774635315, 'learning_rate': 9.563806126346643e-06, 'epoch': 0.53}\n",
            "{'loss': 0.2901, 'grad_norm': 0.042437903583049774, 'learning_rate': 9.128442572523418e-06, 'epoch': 0.55}\n",
            "{'loss': 0.2893, 'grad_norm': 0.03962692990899086, 'learning_rate': 8.694738077799487e-06, 'epoch': 0.56}\n",
            "{'loss': 0.2783, 'grad_norm': 0.041780684143304825, 'learning_rate': 8.263518223330698e-06, 'epoch': 0.57}\n",
            "{'loss': 0.2988, 'grad_norm': 0.04224047064781189, 'learning_rate': 7.835603860618973e-06, 'epoch': 0.59}\n",
            "{'loss': 0.278, 'grad_norm': 0.040542569011449814, 'learning_rate': 7.411809548974792e-06, 'epoch': 0.6}\n",
            "{'loss': 0.2957, 'grad_norm': 0.04034178704023361, 'learning_rate': 6.992942004957271e-06, 'epoch': 0.62}\n",
            "{'loss': 0.2691, 'grad_norm': 0.03883595019578934, 'learning_rate': 6.579798566743314e-06, 'epoch': 0.63}\n",
            "{'loss': 0.2887, 'grad_norm': 0.03946587070822716, 'learning_rate': 6.173165676349103e-06, 'epoch': 0.64}\n",
            "{'loss': 0.268, 'grad_norm': 0.04042750597000122, 'learning_rate': 5.773817382593008e-06, 'epoch': 0.66}\n",
            "{'loss': 0.2663, 'grad_norm': 0.04243028908967972, 'learning_rate': 5.382513867649663e-06, 'epoch': 0.67}\n",
            "{'loss': 0.2815, 'grad_norm': 0.039937954396009445, 'learning_rate': 5.000000000000003e-06, 'epoch': 0.69}\n",
            "{'loss': 0.2827, 'grad_norm': 0.03981532156467438, 'learning_rate': 4.627003916531761e-06, 'epoch': 0.7}\n",
            "{'loss': 0.272, 'grad_norm': 0.04017646238207817, 'learning_rate': 4.264235636489542e-06, 'epoch': 0.71}\n",
            "{'loss': 0.2908, 'grad_norm': 0.03881995379924774, 'learning_rate': 3.912385709912794e-06, 'epoch': 0.73}\n",
            "{'loss': 0.2852, 'grad_norm': 0.04091988131403923, 'learning_rate': 3.5721239031346067e-06, 'epoch': 0.74}\n",
            "{'loss': 0.2821, 'grad_norm': 0.040974073112010956, 'learning_rate': 3.2440979238433977e-06, 'epoch': 0.76}\n",
            "{'loss': 0.2897, 'grad_norm': 0.04128747805953026, 'learning_rate': 2.9289321881345257e-06, 'epoch': 0.77}\n",
            "{'loss': 0.2919, 'grad_norm': 0.040972184389829636, 'learning_rate': 2.6272266318987606e-06, 'epoch': 0.78}\n",
            "{'loss': 0.2675, 'grad_norm': 0.04944310709834099, 'learning_rate': 2.339555568810221e-06, 'epoch': 0.8}\n",
            "{'loss': 0.272, 'grad_norm': 0.04125469550490379, 'learning_rate': 2.0664665970876496e-06, 'epoch': 0.81}\n",
            "{'loss': 0.2968, 'grad_norm': 0.0401521734893322, 'learning_rate': 1.808479557110081e-06, 'epoch': 0.83}\n",
            "{'loss': 0.2825, 'grad_norm': 0.040450725704431534, 'learning_rate': 1.566085541871145e-06, 'epoch': 0.84}\n",
            "{'loss': 0.3087, 'grad_norm': 0.04155230149626732, 'learning_rate': 1.339745962155613e-06, 'epoch': 0.85}\n",
            "{'loss': 0.2939, 'grad_norm': 0.03926434740424156, 'learning_rate': 1.129891668217783e-06, 'epoch': 0.87}\n",
            "{'loss': 0.2819, 'grad_norm': 0.04088444262742996, 'learning_rate': 9.369221296335007e-07, 'epoch': 0.88}\n",
            "{'loss': 0.2785, 'grad_norm': 0.0381874181330204, 'learning_rate': 7.612046748871327e-07, 'epoch': 0.9}\n",
            "{'loss': 0.2843, 'grad_norm': 0.03971501812338829, 'learning_rate': 6.030737921409169e-07, 'epoch': 0.91}\n",
            "{'loss': 0.2822, 'grad_norm': 0.04046123847365379, 'learning_rate': 4.628304925177318e-07, 'epoch': 0.92}\n",
            "{'loss': 0.282, 'grad_norm': 0.041982244700193405, 'learning_rate': 3.4074173710931804e-07, 'epoch': 0.94}\n",
            "{'loss': 0.3026, 'grad_norm': 0.038715165108442307, 'learning_rate': 2.370399288006664e-07, 'epoch': 0.95}\n",
            "{'loss': 0.2819, 'grad_norm': 0.03806982561945915, 'learning_rate': 1.519224698779198e-07, 'epoch': 0.97}\n",
            "{'loss': 0.283, 'grad_norm': 0.04031049460172653, 'learning_rate': 8.555138626189619e-08, 'epoch': 0.98}\n",
            "{'loss': 0.2945, 'grad_norm': 0.039586521685123444, 'learning_rate': 3.805301908254455e-08, 'epoch': 0.99}\n",
            "{'loss': 0.272, 'grad_norm': 0.05442313104867935, 'learning_rate': 9.517784181422018e-09, 'epoch': 1.0}\n",
            "{'train_runtime': 3695.9688, 'train_samples_per_second': 2.476, 'train_steps_per_second': 0.019, 'train_loss': 0.28730813124113613, 'epoch': 1.0}\n",
            "Merging saved LoRA adapters into standalone model weights.\n",
            "Merging LoRA adapter from ckpt/first-run/models/model_iter_1 into base model; saving to ckpt/first-run/models/model_iter_1-merged\n",
            "Merging LoRA adapter from ckpt/first-run/models/model_iter_1/checkpoint-60 into base model; saving to ckpt/first-run/models/model_iter_1/checkpoint-60-merged\n",
            "Merging LoRA adapter from ckpt/first-run/models/model_iter_1/checkpoint-72 into base model; saving to ckpt/first-run/models/model_iter_1/checkpoint-72-merged\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m:  View run \u001b[33mbrisk-forest-2\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251114_115913-q55p38u7/logs\u001b[0m\n",
            "Using merged LoRA model: ckpt/first-run/models/model_iter_1-merged\n",
            " Training completed\n",
            "\n",
            " Iteration 0 completed\n",
            "\n",
            "========================================\n",
            "Self-Training Pipeline Summary\n",
            "========================================\n",
            "Pipeline Directory: ckpt/first-run\n",
            "Iterations Completed: 1 / 1\n",
            "\n",
            "Results by iteration:\n",
            "  Iteration 0: 9338 correct examples\n",
            "\n",
            "Logs:\n",
            "  - Main log: ckpt/first-run/logs/pipeline.log\n",
            "  - Iteration logs: ckpt/first-run/iteration_*/iteration.log\n",
            "\n",
            " All iterations completed successfully!\n",
            " Final model saved to: ckpt/first-run/models/model_iter_1-merged\n",
            "\n",
            "========================================\n",
            "Pipeline finished!\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/first-run/models/model_iter_1-merged \\\n",
        "    --output_dir results \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "hAGHw1LvQDlw"
      },
      "id": "hAGHw1LvQDlw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/first-run/models/model_iter_1-merged \\\n",
        "    --output_dir results \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "38CxfTf28m3o",
        "outputId": "e1ef892a-e256-4e95-a69b-a8bf9baaa31c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "38CxfTf28m3o",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "GSM8K Evaluation Pipeline\n",
            "========================================\n",
            "Model: ckpt/first-run/models/model_iter_1-merged\n",
            "Output Directory: results\n",
            "Run Name: model_iter_1-merged_20251115_060728\n",
            "Dataset Split: test\n",
            "Number of Queries: 2000\n",
            "Max Tokens: 512\n",
            "Temperature: 0.6\n",
            "Top-p: 0.95\n",
            "Top-k: 20\n",
            "Number of Rollouts: 8\n",
            "Tensor Parallel: 1\n",
            "Mode: Zero-shot\n",
            "Chat Template: Enabled\n",
            "Thinking Mode: Disabled\n",
            "========================================\n",
            "\n",
            "[1/2] Running inference...\n",
            "Output will be saved to: results/model_iter_1-merged_20251115_060728_inference.jsonl\n",
            "\n",
            "2025-11-15 06:07:32.677374: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-11-15 06:07:32.694729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763186852.716271   12172 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763186852.722785   12172 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763186852.739114   12172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186852.739143   12172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186852.739145   12172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186852.739147   12172 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-15 06:07:32.743987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 11-15 06:07:39 [__init__.py:216] Automatically detected platform cuda.\n",
            "INFO 11-15 06:07:42 [utils.py:328] non-default args: {'tokenizer': 'ckpt/first-run/models/model_iter_1-merged', 'gpu_memory_utilization': 0.8, 'disable_log_stats': True, 'model': 'ckpt/first-run/models/model_iter_1-merged'}\n",
            "INFO 11-15 06:07:57 [__init__.py:742] Resolved architecture: Qwen3ForCausalLM\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "INFO 11-15 06:07:57 [__init__.py:1815] Using max model len 40960\n",
            "INFO 11-15 06:07:59 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
            "WARNING 11-15 06:08:00 [__init__.py:2974] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
            "2025-11-15 06:08:04.665665: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763186884.687371   12402 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763186884.693851   12402 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763186884.709465   12402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186884.709499   12402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186884.709501   12402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763186884.709503   12402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "INFO 11-15 06:08:12 [__init__.py:216] Automatically detected platform cuda.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:13 [core.py:654] Waiting for init message from front-end.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:13 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='ckpt/first-run/models/model_iter_1-merged', speculative_config=None, tokenizer='ckpt/first-run/models/model_iter_1-merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=ckpt/first-run/models/model_iter_1-merged, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "[W1115 06:08:15.236307023 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:15 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m WARNING 11-15 06:08:15 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:16 [gpu_model_runner.py:2338] Starting to load model ckpt/first-run/models/model_iter_1-merged...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:16 [gpu_model_runner.py:2370] Loading model from scratch...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:16 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.23it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.23it/s]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m \n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:17 [default_loader.py:268] Loading weights took 0.84 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:18 [gpu_model_runner.py:2392] Model loading took 1.1201 GiB and 1.043268 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:26 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/ff3d868903/rank_0_0/backbone for vLLM's torch.compile\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:26 [backends.py:550] Dynamo bytecode transform time: 7.57 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:29 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 2.774 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:30 [monitor.py:34] torch.compile takes 7.57 s in total\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:31 [gpu_worker.py:298] Available KV cache memory: 15.19 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:32 [kv_cache_utils.py:864] GPU KV cache size: 142,208 tokens\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:32 [kv_cache_utils.py:868] Maximum concurrency for 40,960 tokens per request: 3.47x\n",
            "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|| 67/67 [00:02<00:00, 22.39it/s]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:36 [gpu_model_runner.py:3118] Graph capturing finished in 4 secs, took 0.47 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:36 [gpu_worker.py:391] Free memory on device (21.95/22.16 GiB) on startup. Desired GPU memory utilization is (0.8, 17.73 GiB). Actual usage is 1.12 GiB for weight, 1.4 GiB for peak activation, 0.02 GiB for non-torch memory, and 0.47 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=15648680140` to fit into requested memory, or `--kv-cache-memory=20177558528` to fully utilize gpu memory. Current kv cache memory in use is 16311380172 bytes.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=12402)\u001b[0;0m INFO 11-15 06:08:36 [core.py:218] init engine (profile, create kv cache, warmup model) took 18.03 seconds\n",
            "INFO 11-15 06:08:37 [llm.py:295] Supported_tasks: ['generate']\n",
            "INFO 11-15 06:08:37 [__init__.py:36] No IOProcessor plugins requested by the model\n",
            "Adding requests: 100%|| 1319/1319 [00:01<00:00, 1148.54it/s]\n",
            "Processed prompts: 100%|| 10552/10552 [16:36<00:00, 10.59it/s, est. speed input: 935.21 toks/s, output: 2752.92 toks/s]\n",
            "[rank0]:[W1115 06:25:15.745767483 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
            "\n",
            "Inference completed successfully!\n",
            "\n",
            "[2/2] Running evaluation...\n",
            "Evaluation results will be saved to: results/model_iter_1-merged_20251115_060728_evaluation.jsonl\n",
            "\n",
            "Loading data from results/model_iter_1-merged_20251115_060728_inference.jsonl\n",
            "Loaded 10552 examples\n",
            "\n",
            "Basic Evaluation Results:\n",
            "Total examples: 10552\n",
            "Correct answers: 6349\n",
            "Overall Accuracy: 60.17%\n",
            "\n",
            "Detected multiple rollouts: 1319 unique questions with 10552 total rollouts\n",
            "\n",
            "============================================================\n",
            "Multiple Rollout Metrics:\n",
            "============================================================\n",
            "k     avg@k           pass@k         \n",
            "------------------------------------------------------------\n",
            "1     0.5944          0.5944         \n",
            "2     0.5986          0.7119         \n",
            "3     0.6037          0.7650         \n",
            "4     0.6025          0.7885         \n",
            "5     0.6020          0.8074         \n",
            "6     0.6022          0.8271         \n",
            "7     0.6026          0.8370         \n",
            "8     0.6017          0.8423         \n",
            "============================================================\n",
            "\n",
            "Metrics saved to results/model_iter_1-merged_20251115_060728_evaluation_metrics.json\n",
            "\n",
            "Results saved to results/model_iter_1-merged_20251115_060728_evaluation.jsonl\n",
            "\n",
            "========================================\n",
            "Evaluation Pipeline Completed!\n",
            "========================================\n",
            "Results:\n",
            "  - Inference outputs: results/model_iter_1-merged_20251115_060728_inference.jsonl\n",
            "  - Evaluation results: results/model_iter_1-merged_20251115_060728_evaluation.jsonl\n",
            "  - Log file: results/model_iter_1-merged_20251115_060728.log\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase epoch (128)"
      ],
      "metadata": {
        "id": "fYxvzs9YKOXj"
      },
      "id": "fYxvzs9YKOXj"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --total_batch_size 128 --run_name epoch_128"
      ],
      "metadata": {
        "id": "fviKo_zjKSA9"
      },
      "id": "fviKo_zjKSA9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/epoch_128/models/model_iter_1-merged \\\n",
        "    --output_dir results/epoch_128 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "aYbYLS1_Scvr"
      },
      "id": "aYbYLS1_Scvr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/epoch_128/models/model_iter_1-merged \\\n",
        "    --output_dir results/epoch_128 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "8lRG831YSeEr"
      },
      "id": "8lRG831YSeEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase epoch (256)"
      ],
      "metadata": {
        "id": "bNDay-KiIzGv"
      },
      "id": "bNDay-KiIzGv"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --total_batch_size 256 --run_name epoch_256"
      ],
      "metadata": {
        "id": "MD3UEKnTJMhJ"
      },
      "id": "MD3UEKnTJMhJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/epoch_256/models/model_iter_1-merged \\\n",
        "    --output_dir results/epoch_256 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "_1YFTDPsRgT9"
      },
      "id": "_1YFTDPsRgT9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/epoch_256/models/model_iter_1-merged \\\n",
        "    --output_dir results/epoch_256 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "PTLNC951SPvP"
      },
      "id": "PTLNC951SPvP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase queries (3000)"
      ],
      "metadata": {
        "id": "ZQmWzY-OMBA9"
      },
      "id": "ZQmWzY-OMBA9"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --n_queries 3000 --run_name queries_3000"
      ],
      "metadata": {
        "id": "9s1qgYN-MD5W"
      },
      "id": "9s1qgYN-MD5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/queries_3000/models/model_iter_1-merged \\\n",
        "    --output_dir results/queries_3000 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "ekoe-AGTRjw6"
      },
      "id": "ekoe-AGTRjw6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/queries_3000/models/model_iter_1-merged \\\n",
        "    --output_dir results/queries_3000 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "CC1OrtejSNGK"
      },
      "id": "CC1OrtejSNGK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decrease queries (1000)"
      ],
      "metadata": {
        "id": "lM1N-KByMSzQ"
      },
      "id": "lM1N-KByMSzQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --n_queries 1000 --run_name queries_1000"
      ],
      "metadata": {
        "id": "vW9LAzaaMWaH"
      },
      "id": "vW9LAzaaMWaH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/queries_1000/models/model_iter_1-merged \\\n",
        "    --output_dir results/queries_1000 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "Gnb-oRv9RoBl"
      },
      "id": "Gnb-oRv9RoBl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/queries_1000/models/model_iter_1-merged \\\n",
        "    --output_dir results/queries_1000 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "V30vRcT4SL_Y"
      },
      "id": "V30vRcT4SL_Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase lr (4e-5)"
      ],
      "metadata": {
        "id": "CMSprCe0MaAm"
      },
      "id": "CMSprCe0MaAm"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --learning_rate 4e-5 --run_name \"lr_4e-5\""
      ],
      "metadata": {
        "id": "e5dD8PT2Nj4W",
        "outputId": "5194e8a5-7379-45d2-f85e-032ffe88948a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e5dD8PT2Nj4W",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash \"scripts/run_gsm8k_eval.sh ckpt/lr_4e-5/models/model_iter_1-merged\" \\\n",
        "    --output_dir \"results/lr_4e-5\" \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "O-bVo6-LRqgS"
      },
      "id": "O-bVo6-LRqgS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash \"scripts/run_gsm8k_eval.sh ckpt/lr_4e-5/models/model_iter_1-merged\" \\\n",
        "    --output_dir \"results/lr_4e-5\" \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "W0GQ1QYVSKWp"
      },
      "id": "W0GQ1QYVSKWp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase lr (1e-5)"
      ],
      "metadata": {
        "id": "Mtlkrf5nNycx"
      },
      "id": "Mtlkrf5nNycx"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --learning_rate 1e-5 --run_name \"lr_1e-5\""
      ],
      "metadata": {
        "id": "O9-qsGO3N29Z"
      },
      "id": "O9-qsGO3N29Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash \"scripts/run_gsm8k_eval.sh ckpt/lr_1e-5/models/model_iter_1-merged\" \\\n",
        "    --output_dir \"results/lr_1e-5\" \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "ib03Ntu7RyQI"
      },
      "id": "ib03Ntu7RyQI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash \"scripts/run_gsm8k_eval.sh ckpt/lr_1e-5/models/model_iter_1-merged\" \\\n",
        "    --output_dir \"results/lr_1e-5\" \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "7cKISfoiSEsm"
      },
      "id": "7cKISfoiSEsm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Increase LoRA rank (128)"
      ],
      "metadata": {
        "id": "_lldD-rLOM9F"
      },
      "id": "_lldD-rLOM9F"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --lora_r 128 --run_name rank_128"
      ],
      "metadata": {
        "id": "rYmbAiCRORl0"
      },
      "id": "rYmbAiCRORl0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/rank_128/models/model_iter_1-merged \\\n",
        "    --output_dir results/rank_128 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "FOtwG7IbR1ek"
      },
      "id": "FOtwG7IbR1ek",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/rank_128/models/model_iter_1-merged \\\n",
        "    --output_dir results/rank_128 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "rjh0rzoZSD3l"
      },
      "id": "rjh0rzoZSD3l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decrease LoRA rank (32)"
      ],
      "metadata": {
        "id": "8mCBekXZOhxf"
      },
      "id": "8mCBekXZOhxf"
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && \\\n",
        "export WANDB_API_KEY=\"cdb87cd68d7a18cd6d0a4e34d52b1ef4b41c20e3\" && \\\n",
        "export WANDB_PROJECT=\"COMP4901B-Homework3\" && \\\n",
        "export CUDA_VISIBLE_DEVICES=\"0\" && \\\n",
        "bash scripts/self_train_gsm8k.sh Qwen3-0.6B --lora_r 32 --run_name rank_32"
      ],
      "metadata": {
        "id": "iflfrd2GOkdW"
      },
      "id": "iflfrd2GOkdW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 1\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/rank_32/models/model_iter_1-merged \\\n",
        "    --output_dir results/rank_32 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 1 \\"
      ],
      "metadata": {
        "id": "pCP5kCyaR_or"
      },
      "id": "pCP5kCyaR_or",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation of iteration 1 rollout 8\n",
        "!cd /content/drive/MyDrive/COMP4901B-Homework3/COMP4901B-LLMs/assignment3 && bash scripts/run_gsm8k_eval.sh ckpt/rank_32/models/model_iter_1-merged \\\n",
        "    --output_dir results/rank_32 \\\n",
        "    --temperature 0.6 \\\n",
        "    --max_tokens 512 \\\n",
        "    --top_p 0.95 \\\n",
        "    --top_k 20 \\\n",
        "    --n_rollouts 8 \\\n",
        "    --n_queries 2000"
      ],
      "metadata": {
        "id": "qjiwnnfJSDM3"
      },
      "id": "qjiwnnfJSDM3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}